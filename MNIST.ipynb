{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1A2oupZJU-L3Si58r8Sd-D1eZ6I0Bd7_C",
      "authorship_tag": "ABX9TyPY6LICVfAV3zko4pqpNipt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anh1811/baocao/blob/main/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGZxbNeliCwE"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.optimize as opt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "ZdD_9Wo9py_E",
        "outputId": "d682e8b0-1b26-42bf-c968-5e8b02043fc4"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-e270d95ecc86>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    git remote add origin https://github.com/anh1811/baocao.git\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtwTE45Fn6p3"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSCnhdNMoAGq",
        "outputId": "2035f5ec-f572-4d5a-8137-ff236b9b08ab"
      },
      "source": [
        "x_train[2,:][np.newaxis,:][0,:].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsFzSIuAoTgj"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0],-1)\n",
        "y_train = y_train\n",
        "x_val = x_test[0:5000].reshape(5000,-1)\n",
        "y_val = y_test[0:5000]\n",
        "x_test = x_test[5000:10000].reshape(5000,-1)\n",
        "y_test = y_test[5000:10000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hwqjk1cu4l_",
        "outputId": "cdbf1cc4-1332-4669-bc06-5f4ed0ed8041"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-STYmTT6ySaN"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x));\n",
        "def sigmoidGradient(x):\n",
        "  return sigmoid(x)*(1-sigmoid(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr5NMYIRQ8ss"
      },
      "source": [
        "def nnCostFunction1(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, Lambda):\n",
        "  Theta1 = nn_params[0:hidden_layer_size * (input_layer_size + 1)].reshape(\\\n",
        "                          hidden_layer_size, (input_layer_size + 1))\n",
        "  Theta2 = nn_params[hidden_layer_size * (input_layer_size + 1):].reshape(\\\n",
        "                          num_labels, (hidden_layer_size + 1))\n",
        "  I = np.eye(num_labels)\n",
        "  X = np.append(1,X) #333\n",
        "  z2 = np.dot(X,Theta1.T) # X * theta1' (m,hiddenlayersize)\n",
        "  a2 = sigmoid(z2)\n",
        "  a2 = np.append(1,a2) # m * hiddenlayersize + 1\n",
        "  z3 = np.dot(a2,Theta2.T) # m * 10\n",
        "  a3 = sigmoid(z3) #10\n",
        "  J = 0\n",
        "  Theta1_grad = np.zeros((hidden_layer_size,input_layer_size+1))\n",
        "  Theta2_grad = np.zeros((num_labels,hidden_layer_size+1))\n",
        "  y = I[int(y)]\n",
        "  J = - np.dot(np.log10(a3[np.newaxis,:]),y) - (np.log10((1 - a3)[np.newaxis,:]) @ (1 -y))\n",
        "  delta3 = a3 - y\n",
        "  delta2 = np.dot(Theta2.T,delta3) * sigmoidGradient(np.append(1,z2))  #(hls+1,)\n",
        "  delta2 = delta2[1:] #(hls,)\n",
        "  Theta1_grad += np.dot(delta2[:,np.newaxis],X[np.newaxis,:]) # hls, ils+1\n",
        "  Theta2_grad += np.dot(delta3.reshape(num_labels,1),a2.reshape(1,hidden_layer_size+1)) # 10,hls+1\n",
        "\n",
        "  J += Lambda/2*(np.sum(Theta1[:,1:]**2) + np.sum(Theta2[:,1:]**2))\n",
        "  Theta1_grad = Theta1_grad \n",
        "  Theta1_grad[:,1:] += Lambda * Theta1[:,1:]\n",
        "  Theta2_grad = Theta2_grad \n",
        "  Theta2_grad[:,1:] += Lambda * Theta2[:,1:]\n",
        "\n",
        "  grad = np.append(Theta1_grad, Theta2_grad)\n",
        "  return [J,grad]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIpO3gd_cpcm"
      },
      "source": [
        "def nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, Lambda):\n",
        "  Theta1 = np.reshape(nn_params[0:hidden_layer_size * (input_layer_size + 1)],\\\n",
        "                          [hidden_layer_size, (input_layer_size + 1)])\n",
        "  Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):],\\\n",
        "                          [num_labels, (hidden_layer_size + 1)])\n",
        "  m = X.shape[0];\n",
        "  I = np.eye(num_labels)\n",
        "  X = np.concatenate((np.ones((m,1)),X),1) \n",
        "  z2 = np.dot(X,Theta1.T) \n",
        "  a2 = sigmoid(z2)\n",
        "  a2 = np.concatenate((np.ones((m,1)),a2),1) \n",
        "  z3 = np.dot(a2,Theta2.T) \n",
        "  a3 = sigmoid(z3)\n",
        "  J = 0\n",
        "  Theta1_grad = np.zeros((hidden_layer_size,input_layer_size+1))\n",
        "  Theta2_grad = np.zeros((num_labels,hidden_layer_size+1))\n",
        "  for i in range(0,m):\n",
        "    yi = I[int(y[i])] \n",
        "    J += (-np.dot(np.log10(a3[i,:]),yi) - np.log10((1 - a3[i,:])) @ (1 -yi)) * 1/m\n",
        "    delta3 = a3[i,:] - yi\n",
        "    delta2 = np.dot(Theta2.T,delta3) * sigmoidGradient(np.append(1,z2[i,:])) \n",
        "    delta2 = delta2[1:] \n",
        "    Theta1_grad += np.dot(delta2[:,np.newaxis],X[i,:][np.newaxis,:])\n",
        "    Theta2_grad += np.dot(delta3.reshape(num_labels,1),a2[i,:].reshape(1,hidden_layer_size + 1))\n",
        "  J += Lambda/(2*m)*(np.sum(Theta1[0:,1:]**2) + np.sum(Theta2[0:,1:]**2))\n",
        "  Theta1_grad = Theta1_grad/m \n",
        "  Theta1_grad[0:,1:] += Lambda/m * Theta1[0:,1:]\n",
        "  Theta2_grad = Theta2_grad/m \n",
        "  Theta2_grad[0:,1:] += Lambda/m * Theta2[0:,1:]\n",
        "\n",
        "  grad = np.append(Theta1_grad, Theta2_grad)\n",
        "  return [J,grad]\n",
        "\n",
        "\n",
        "\n",
        "def randInitializeWeights(L_in, L_out):\n",
        "  epsilon_init = np.sqrt(6)/np.sqrt(L_in+L_out)\n",
        "  W = np.random.random((L_out, 1+L_in))*(2*epsilon_init) - epsilon_init\n",
        "  return W\n",
        "\n",
        "def featureNormalize(X):\n",
        "  mu = np.mean(X,axis =0)\n",
        "  X_norm = X-mu\n",
        "  sigma = np.std(X_norm,axis =0, ddof=1)\n",
        "  sigma_1 = np.where(sigma==0,1,sigma)\n",
        "  X_norm = X_norm/sigma_1\n",
        "  return X_norm, mu, sigma\n",
        "\n",
        "def predict(Theta1, Theta2, X):\n",
        "\n",
        "  m = X.shape[0];\n",
        "  num_labels = Theta2.shape[0];\n",
        "\n",
        "  h1 = sigmoid(np.concatenate((np.ones((m,1)),X),1) @ Theta1.T)\n",
        "  h2 = sigmoid(np.concatenate((np.ones((m,1)),h1),1) @ Theta2.T)\n",
        "\n",
        "  p = np.argmax(h2,axis=1)\n",
        "\n",
        "  return p\n",
        "\n",
        "def pca(X):\n",
        "  m = X.shape[0];\n",
        "  Sigma = (1/m)*np.dot(X.T,X)\n",
        "  U, S, Vh = np.linalg.svd(Sigma)\n",
        "  return (U,S)\n",
        "\n",
        "def projectData(X, U, K):\n",
        "  Ureduce = U[:,0:K]\n",
        "  Z = np.dot(X,Ureduce)\n",
        "  return Z\n",
        "\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfpNlrBdleFV",
        "outputId": "494df522-8bf9-432d-c64a-6f1710d32f2b"
      },
      "source": [
        "x_train, mu_train, sigma_train = featureNormalize(x_train)\n",
        "x_test, mu_test, sigma_test =featureNormalize(x_test)\n",
        "x_val, mu_val, sigma_val = featureNormalize(x_val)\n",
        "print(\"Normalize Data! Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalize Data! Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEL_Pe1BVlR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff2faf4-e286-45fb-e380-2990f7f5225e"
      },
      "source": [
        "K = 1\n",
        "var = 0\n",
        "U,S = pca(x_train)\n",
        "S_sum = S.sum() \n",
        "while(var < 0.95):\n",
        "  var = S[0:K].sum()/S_sum\n",
        "  K += 1\n",
        "  print(var)\n",
        "print(K) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.05646716919741764\n",
            "0.09724988908210876\n",
            "0.1346436932980204\n",
            "0.16349484175413345\n",
            "0.18870592801066705\n",
            "0.21064862765748582\n",
            "0.22988207152080636\n",
            "0.24734006380483683\n",
            "0.2626909868507977\n",
            "0.2767081828674872\n",
            "0.2901256130661941\n",
            "0.3021630324608486\n",
            "0.31330872795849646\n",
            "0.3242079635196384\n",
            "0.3344944557556942\n",
            "0.344439321393158\n",
            "0.35380315419525726\n",
            "0.3630136108505784\n",
            "0.3719479786271314\n",
            "0.38064710481471714\n",
            "0.38892073500511937\n",
            "0.3969549086989737\n",
            "0.4046033637025235\n",
            "0.4120210883417664\n",
            "0.4191740170214982\n",
            "0.426092485336152\n",
            "0.4329338449752703\n",
            "0.43950059043741635\n",
            "0.44581735767560526\n",
            "0.4519465560669777\n",
            "0.4579091090207258\n",
            "0.4637862731772543\n",
            "0.4695021901693696\n",
            "0.4751252643341362\n",
            "0.4806720843583386\n",
            "0.4860562681005487\n",
            "0.49136809059713804\n",
            "0.49656414661403103\n",
            "0.5016462591601256\n",
            "0.5064463148680689\n",
            "0.5112108730680837\n",
            "0.5159022666681029\n",
            "0.5204457562288387\n",
            "0.5249592140941933\n",
            "0.529428848105275\n",
            "0.5338626796596289\n",
            "0.5382448343446772\n",
            "0.5425486518569812\n",
            "0.5468174308633516\n",
            "0.5510539010352965\n",
            "0.5551008622486074\n",
            "0.5590953362835827\n",
            "0.5630698974739515\n",
            "0.5670081054767824\n",
            "0.5708662413790714\n",
            "0.5746566681235827\n",
            "0.5784106949313484\n",
            "0.5821184533847855\n",
            "0.5857678971937282\n",
            "0.5893609029276439\n",
            "0.5928847245878871\n",
            "0.5963626610356565\n",
            "0.5998067741200338\n",
            "0.6032054552906121\n",
            "0.6065650007310006\n",
            "0.6099138602781872\n",
            "0.6132324971722056\n",
            "0.6164627567158046\n",
            "0.6196255264463593\n",
            "0.6227579689421648\n",
            "0.625865283251375\n",
            "0.6289377122396742\n",
            "0.6319868542264817\n",
            "0.6350140260321782\n",
            "0.6380088792648844\n",
            "0.6409864909900674\n",
            "0.6439370066383326\n",
            "0.6468413879734959\n",
            "0.6497099498668303\n",
            "0.6525667273326586\n",
            "0.6554007051240544\n",
            "0.6582269765513933\n",
            "0.6610224871187379\n",
            "0.663815540710939\n",
            "0.6666007326342651\n",
            "0.6693752872896148\n",
            "0.6721342953444733\n",
            "0.6748765685745328\n",
            "0.6775906746242142\n",
            "0.6802833041068259\n",
            "0.682948147479018\n",
            "0.6855839603822577\n",
            "0.6882135762720305\n",
            "0.690823914467602\n",
            "0.6934121838098767\n",
            "0.6959739479980767\n",
            "0.6985124065861161\n",
            "0.7010168791960498\n",
            "0.7034951731095501\n",
            "0.7059455086308856\n",
            "0.7083689753750182\n",
            "0.7107896133387762\n",
            "0.7131783677576535\n",
            "0.7155529148132784\n",
            "0.7179089989226964\n",
            "0.7202395311843399\n",
            "0.7225193318750939\n",
            "0.7247810740348326\n",
            "0.7270093893933132\n",
            "0.7292338107275365\n",
            "0.7314155045154517\n",
            "0.733588072541983\n",
            "0.7357308404879537\n",
            "0.7378502175986384\n",
            "0.7399599377784826\n",
            "0.7420332399067586\n",
            "0.7440808512420887\n",
            "0.7461245332112355\n",
            "0.7481486182309511\n",
            "0.7501532399167187\n",
            "0.7521414596748022\n",
            "0.7540936154168982\n",
            "0.7560309885620586\n",
            "0.7579520208538204\n",
            "0.7598691795811522\n",
            "0.7617672005954478\n",
            "0.7636380953845212\n",
            "0.7655034521373125\n",
            "0.7673166518925177\n",
            "0.7691167045676096\n",
            "0.770908644970301\n",
            "0.7726983772074708\n",
            "0.7744678816540032\n",
            "0.7762294587500416\n",
            "0.7779774264522603\n",
            "0.7797072737284385\n",
            "0.7814274401678983\n",
            "0.783114711418388\n",
            "0.7847998812696947\n",
            "0.7864682963625722\n",
            "0.7881154808077409\n",
            "0.7897612302510345\n",
            "0.7914041660192309\n",
            "0.7930190238541786\n",
            "0.7946239264939244\n",
            "0.7962130491952819\n",
            "0.7977879444426591\n",
            "0.7993471219151449\n",
            "0.8009035014126622\n",
            "0.8024501579655463\n",
            "0.8039905869721812\n",
            "0.8055066334950002\n",
            "0.8070093491677414\n",
            "0.8084969548220423\n",
            "0.8099720091254476\n",
            "0.8114402107433196\n",
            "0.8128982385711198\n",
            "0.8143539151285244\n",
            "0.815801283479486\n",
            "0.8172302349281647\n",
            "0.8186408130925851\n",
            "0.8200401991689075\n",
            "0.8214372914253261\n",
            "0.8228326217961557\n",
            "0.8242261716791605\n",
            "0.8256184234258018\n",
            "0.8270061549344543\n",
            "0.8283895516788162\n",
            "0.8297677123669641\n",
            "0.8311361593821706\n",
            "0.8324978143753295\n",
            "0.8338560384438455\n",
            "0.8351930517797675\n",
            "0.8365221061732486\n",
            "0.8378327005396393\n",
            "0.8391356320771957\n",
            "0.8404288754202808\n",
            "0.8417112823937659\n",
            "0.8429853500166115\n",
            "0.8442535715321985\n",
            "0.8455067889001306\n",
            "0.846747236656106\n",
            "0.8479770719752134\n",
            "0.8491932515174799\n",
            "0.8504083140863183\n",
            "0.8516083389454027\n",
            "0.8527992080851724\n",
            "0.8539881529866417\n",
            "0.8551641946073254\n",
            "0.8563317966663009\n",
            "0.8574941356961535\n",
            "0.8586421185152948\n",
            "0.8597791538571424\n",
            "0.860906352767922\n",
            "0.8620269048466295\n",
            "0.8631209925632859\n",
            "0.8642064480701839\n",
            "0.8652767325916669\n",
            "0.8663407437498614\n",
            "0.8673954883719325\n",
            "0.8684417732030784\n",
            "0.869477811618067\n",
            "0.8705104922910452\n",
            "0.8715312246371222\n",
            "0.8725394724105099\n",
            "0.8735410513427229\n",
            "0.8745389099485716\n",
            "0.8755308432616709\n",
            "0.8765081179002043\n",
            "0.8774766116649227\n",
            "0.8784346604219332\n",
            "0.8793910283576385\n",
            "0.8803387567635382\n",
            "0.8812852300097672\n",
            "0.8822289350001813\n",
            "0.8831556811764125\n",
            "0.8840730835090054\n",
            "0.8849817617066881\n",
            "0.8858792313627428\n",
            "0.8867707980071627\n",
            "0.8876586087091413\n",
            "0.8885374952000484\n",
            "0.8894066509170108\n",
            "0.890268774445893\n",
            "0.8911293321488986\n",
            "0.8919746851153573\n",
            "0.8928147769791356\n",
            "0.8936505027318715\n",
            "0.8944745252060349\n",
            "0.8952953055667852\n",
            "0.8961082734208361\n",
            "0.8969184598814309\n",
            "0.8977104303844171\n",
            "0.8984937148639539\n",
            "0.8992724792141563\n",
            "0.9000439834875468\n",
            "0.9008103551542114\n",
            "0.901560525488535\n",
            "0.9023040611136809\n",
            "0.9030430547490487\n",
            "0.9037754859378929\n",
            "0.9045025597971509\n",
            "0.9052280953816294\n",
            "0.9059448682896741\n",
            "0.9066559096384263\n",
            "0.9073584286893358\n",
            "0.9080529464294137\n",
            "0.9087471032512154\n",
            "0.9094265701502624\n",
            "0.9101049857278831\n",
            "0.9107813812080595\n",
            "0.9114528736541914\n",
            "0.9121161592514623\n",
            "0.912771232347974\n",
            "0.913423060412916\n",
            "0.9140675565152396\n",
            "0.9147088933343351\n",
            "0.9153452205677041\n",
            "0.9159773498545452\n",
            "0.9166052181919307\n",
            "0.9172292781440139\n",
            "0.9178494846048072\n",
            "0.9184585063628107\n",
            "0.9190643597817308\n",
            "0.9196629401092027\n",
            "0.9202547971391638\n",
            "0.9208384489838516\n",
            "0.9214192106146253\n",
            "0.9219944444951382\n",
            "0.9225670739499301\n",
            "0.9231367602404457\n",
            "0.9237006900764502\n",
            "0.9242594971126616\n",
            "0.9248160642770882\n",
            "0.9253677708474476\n",
            "0.9259179744911834\n",
            "0.9264626182022404\n",
            "0.9270033417816751\n",
            "0.9275421188788769\n",
            "0.9280745643626955\n",
            "0.9286041078746833\n",
            "0.9291303090668755\n",
            "0.9296526934515807\n",
            "0.9301715113085601\n",
            "0.9306863161482791\n",
            "0.9311946488451593\n",
            "0.9317019943262916\n",
            "0.9322050988453047\n",
            "0.9327058668763165\n",
            "0.9332029090730111\n",
            "0.933695217646509\n",
            "0.9341780545986682\n",
            "0.9346576094952176\n",
            "0.9351345222648886\n",
            "0.9356105248150371\n",
            "0.9360816293369525\n",
            "0.9365476289882712\n",
            "0.9370064509047376\n",
            "0.9374631988963272\n",
            "0.9379126057657091\n",
            "0.9383591873106851\n",
            "0.9388018429597085\n",
            "0.93924022814769\n",
            "0.9396784228171547\n",
            "0.9401107474356114\n",
            "0.9405414478082736\n",
            "0.9409662184594395\n",
            "0.9413874730715199\n",
            "0.9418067073567472\n",
            "0.9422218862819708\n",
            "0.9426351615373856\n",
            "0.9430455097582543\n",
            "0.9434539619463784\n",
            "0.9438577314302369\n",
            "0.9442592620946697\n",
            "0.9446577144774029\n",
            "0.9450529748470724\n",
            "0.9454450682251777\n",
            "0.9458351514799648\n",
            "0.9462218849924005\n",
            "0.9466080916916976\n",
            "0.9469911253044807\n",
            "0.9473701778496375\n",
            "0.9477462313303189\n",
            "0.9481214613288741\n",
            "0.9484919802138826\n",
            "0.9488585332361134\n",
            "0.9492223421670172\n",
            "0.9495818102482029\n",
            "0.9499400669147186\n",
            "0.9502951572319135\n",
            "332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FisW8txLl2cb"
      },
      "source": [
        "# Found from above algorithm\n",
        "x_train = projectData(x_train, U, K)\n",
        "x_test = projectData(x_test,U,K)\n",
        "x_val = projectData(x_val,U,K)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHoLxhcM3FTK"
      },
      "source": [
        "X = np.concatenate((x_train,y_train[:,np.newaxis]), 1)\n",
        "np.random.shuffle(X)\n",
        "x_train = X[:,:-1]\n",
        "y_train = X[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJuIWXpH3HVR",
        "outputId": "86d4054d-eaf7-49e0-bdd1-7c9ae53c9bae"
      },
      "source": [
        "I = np.eye(num_labels)\n",
        "I[int(y_train[100])] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHMLyTxan9jK",
        "outputId": "22eff4fc-7478-4da7-9553-c722d2f55632"
      },
      "source": [
        "input_layer_size  = K\n",
        "hidden_layer_size = 64\n",
        "num_labels = 10\n",
        "\n",
        "\n",
        "print('\\nInitializing Neural Network Parameters ...\\n')\n",
        "\n",
        "initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
        "initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
        "initial_nn_params = np.append(initial_Theta1,initial_Theta2)\n",
        "\n",
        "# num_iters = 150\n",
        "# j_avg = 1\n",
        "\n",
        "# Lambda_vec = [0.3,1, 3]\n",
        "nn_params = initial_nn_params\n",
        "#Lambda_vec_len = len(Lambda_vec)\n",
        "val_result_max =0 #Will be changed later\n",
        "\n",
        "m = x_train.shape[0]\n",
        "for j in range(10):\n",
        "  for i in range(m):\n",
        "    J,grad = nnCostFunction1(nn_params, input_layer_size, hidden_layer_size, num_labels, x_train[i,:], y_train[i], 0.001)\n",
        "    nn_params -= 0.1*grad\n",
        "    i += 1\n",
        "  j += 1\n",
        "\n",
        "\n",
        "Theta1 = np.reshape(nn_params[0:hidden_layer_size * (input_layer_size + 1)],\\\n",
        "                           [hidden_layer_size, (input_layer_size + 1)])\n",
        "Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):],\\\n",
        "                           [num_labels, (hidden_layer_size + 1)])\n",
        "pred_val = predict(Theta1, Theta2, x_val);\n",
        "val_result = (np.mean(pred_val==y_val) * 100)\n",
        "pred_train = predict(Theta1, Theta2, x_train);\n",
        "train_result = (np.mean(pred_train==y_train) * 100)\n",
        "#   print(np.mean(pred_val==y_val) * 100)\n",
        "\n",
        "\n",
        "# for i in range(1):\n",
        "#   print(f\"With Lambda = {Lambda_vec[1]}, {num_iters} iters\")\n",
        "#   val_result =0\n",
        "\n",
        "#   result = opt.minimize(nnCostFunction, x0=initial_nn_params, args=(\\\n",
        "#         input_layer_size, hidden_layer_size, num_labels, x_train, y_train, Lambda_vec[1])\\\n",
        "#         ,method='L-BFGS-B',jac=True,options={'maxiter':num_iters})\n",
        "      \n",
        "#   nn_params = result.x\n",
        "\n",
        "\n",
        "#   Theta1 = np.reshape(nn_params[0:hidden_layer_size * (input_layer_size + 1)],\\\n",
        "#                           [hidden_layer_size, (input_layer_size + 1)])\n",
        "#   Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):],\\\n",
        "#                           [num_labels, (hidden_layer_size + 1)])\n",
        "#   pred_val = predict(Theta1, Theta2, x_val);\n",
        "\n",
        "#   val_result = (np.mean(pred_val==y_val) * 100)\n",
        "#   print(np.mean(pred_val==y_val) * 100)\n",
        "\n",
        "\n",
        "#   if val_result >val_result_max:\n",
        "#     val_result_max = val_result\n",
        "#     Lambda = Lambda_vec[i]\n",
        "#     final_nn_params = nn_params\n",
        "\n",
        "\n",
        "print(f\"The accuracy on validate set is about {val_result}%\\n\")\n",
        "print(f\"The accuracy on train set is about {train_result}%\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Initializing Neural Network Parameters ...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The accuracy on validate set is about 89.92%\n",
            "\n",
            "The accuracy on train set is about 92.56166666666667%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6XzMPKi7Kj-",
        "outputId": "e5c89ca3-07f0-4724-deaf-dcf3be6e82b9"
      },
      "source": [
        "np.isscalar(y_test[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nobS4wWG1L4Z"
      },
      "source": [
        "# # J = np.save(r\"/content/drive/MyDrive/MNIST problem\",final_nn_params,allow_pickle = False)\n",
        "# nn_params = np.load(r\"/content/drive/MyDrive/MNIST problem.npy\")\n",
        "Theta1 = np.reshape(nn_params[0:hidden_layer_size * (input_layer_size + 1)],\\\n",
        "                        [hidden_layer_size, (input_layer_size + 1)])\n",
        "Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):],\\\n",
        "                        [num_labels, (hidden_layer_size + 1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbNXacoSFb5Y",
        "outputId": "69e40035-0c6d-4ab6-e2d3-74057a0732b9"
      },
      "source": [
        "pred_train = predict(Theta1, Theta2, x_train);\n",
        "print(f\"The accuracy on train set is about {np.mean(pred_train==y_train) * 100}%\")\n",
        "\n",
        "pred_test = predict(Theta1, Theta2, x_test);\n",
        "print(f\"The accuracy on test set is about {np.mean(pred_test==y_test) * 100}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy on train set is about 11.236666666666666%\n",
            "The accuracy on test set is about 11.28%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHbMtcw1vMbu"
      },
      "source": [
        "import pandas as pd\n",
        "X = np.array(pd.read_csv(\"/content/sample_data/mnist_test.csv\")) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQZ64jqHxjZa",
        "outputId": "227832f8-d4fb-451e-d074-9e9be92d4cfe"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9999, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iXDU_Xow4rs",
        "outputId": "460a938b-04fb-46fc-cc9a-411339b332eb"
      },
      "source": [
        "x = np.array(X[:,1:])\n",
        "y = np.array(X[:,0])\n",
        "x, mu, sigma = featureNormalize(x)\n",
        "x = projectData(x, U, K)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 0, ..., 4, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2lXR2eAxyu0",
        "outputId": "677d7ad9-c317-4f9b-f922-b5b4aec9e742"
      },
      "source": [
        "pre = predict(Theta1,Theta2,x);\n",
        "print(f\"The accuracy on test set is about {np.mean(pre==y) * 100}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy on test set is about 95.6095609560956%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}