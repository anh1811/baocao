{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DogvsCat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1klcxsoe_PMbOttT1T9BY0JLu_fQqfeL3",
      "authorship_tag": "ABX9TyMOCoABTmujxwtg+NvjW9jJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anh1811/baocao/blob/main/DogvsCat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlWtzIDlS_cp",
        "outputId": "11b79108-ab06-4516-ec96-6e12a17132d0"
      },
      "source": [
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.26-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_1WUKA-SK2Y"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ew21JCGTyes",
        "outputId": "e6b1036d-da8c-4a5d-e3b3-d7e87aba8b31"
      },
      "source": [
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgUv2P3KUgmg"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ9H5hFUUkIH"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.applications import vgg16\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "import numpy as np\n",
        "import random\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITIwl2w9WMSj"
      },
      "source": [
        "import zipfile as zp\n",
        "os.makedirs('content/data', exist_ok=True)\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Data/dogs-vs-cats-redux-kernels-edition.zip'\n",
        "base_zip = zp.ZipFile(base_dir)\n",
        "\n",
        "base_zip.extractall('../data')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyHozN1mpz8O"
      },
      "source": [
        "train_dir = '../data/train'\n",
        "test_dir = '../data/test'\n",
        "\n",
        "train_zip = zp.ZipFile('../data/train.zip')\n",
        "train_zip.extractall('../data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-dtOlFxdtM1"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nEmo4RTdt2V"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szoQq2psWuXk"
      },
      "source": [
        "image_path = list(os.listdir(train_dir))\n",
        "\n",
        "random.shuffle(image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJF4grkIW201"
      },
      "source": [
        "labels = [p.split('.')[-3] for p in image_path]\n",
        "\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnc3EYyuW36L"
      },
      "source": [
        "list_image = []\n",
        "for imagePath in image_path:\n",
        "    path = os.path.join(train_dir,imagePath)\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.resize(image, (128,128))\n",
        "    image = np.array(image)\n",
        "    image = np.expand_dims(image, 0)\n",
        "    image = imagenet_utils.preprocess_input(image)\n",
        "    list_image.append(image)\n",
        "    \n",
        "list_image = np.vstack(list_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CoOZ7jU-U1j",
        "outputId": "14780b77-fbe2-44de-9ed7-5c67e4b39538"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "# these are a new feature in TF 2.2\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "\n",
        "pretrained_base = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "model = keras.Sequential([\n",
        "    # Base\n",
        "    pretrained_base,\n",
        "    # Head\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation = 'relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYKxcviHUEvp"
      },
      "source": [
        "X_train, y_train = list_image[:20000], labels[:20000]\n",
        "X_test, y_test = list_image[20000:25000], labels[20000:25000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9kcgYqFUMEV"
      },
      "source": [
        "# augmentation cho training data\n",
        "aug_train = ImageDataGenerator(rescale=1./255, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, \n",
        "                         zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
        "# augementation cho test\n",
        "aug_test= ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN8B6Lo21YSy"
      },
      "source": [
        "pretrained_base = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(128, 128, 3)))\n",
        "pretrained_base.trainable = False\n",
        "\n",
        "model = keras.Sequential([\n",
        "    # Base\n",
        "    pretrained_base,\n",
        "    # Head\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "# train model\n",
        "opt = 'adam'\n",
        "model.compile(opt, 'binary_crossentropy', ['binary_accuracy'])\n",
        "numOfEpoch = 25\n",
        "H = model.fit_generator(aug_train.flow(X_train, y_train, batch_size=64), \n",
        "                        steps_per_epoch=34,\n",
        "                        validation_data=(aug_test.flow(X_val, y_val, batch_size=64)),\n",
        "                        validation_steps=34,\n",
        "                        epochs=numOfEpoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgNPmF8_UOGv",
        "outputId": "b9c61623-d0d7-4f2b-d400-c1f8f0041326"
      },
      "source": [
        "for layer in pretrained_base.layers:\n",
        "    layer.trainable = False\n",
        "# opt = RMSprop(0.001)\n",
        "opt = 'adam'\n",
        "model.compile(opt, 'binary_crossentropy', ['binary_accuracy'])\n",
        "numOfEpoch = 25\n",
        "H = model.fit_generator(aug_train.flow(X_train, y_train, batch_size=64), \n",
        "                        steps_per_epoch=len(X_train)/64,\n",
        "                        validation_data=(aug_test.flow(X_test, y_test, batch_size=64)),\n",
        "                        validation_steps=len(X_test)/64,\n",
        "                        epochs=numOfEpoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "312/312 [==============================] - 119s 273ms/step - loss: 0.4028 - binary_accuracy: 0.8176 - val_loss: 0.2438 - val_binary_accuracy: 0.8988\n",
            "Epoch 2/25\n",
            "312/312 [==============================] - 82s 261ms/step - loss: 0.3337 - binary_accuracy: 0.8512 - val_loss: 0.2455 - val_binary_accuracy: 0.8940\n",
            "Epoch 3/25\n",
            "312/312 [==============================] - 83s 267ms/step - loss: 0.3220 - binary_accuracy: 0.8580 - val_loss: 0.2614 - val_binary_accuracy: 0.8882\n",
            "Epoch 4/25\n",
            "312/312 [==============================] - 82s 262ms/step - loss: 0.3113 - binary_accuracy: 0.8665 - val_loss: 0.2280 - val_binary_accuracy: 0.9058\n",
            "Epoch 5/25\n",
            "312/312 [==============================] - 82s 262ms/step - loss: 0.3036 - binary_accuracy: 0.8669 - val_loss: 0.2273 - val_binary_accuracy: 0.9048\n",
            "Epoch 6/25\n",
            "312/312 [==============================] - 83s 264ms/step - loss: 0.2923 - binary_accuracy: 0.8715 - val_loss: 0.2212 - val_binary_accuracy: 0.9120\n",
            "Epoch 7/25\n",
            "312/312 [==============================] - 83s 265ms/step - loss: 0.2896 - binary_accuracy: 0.8713 - val_loss: 0.2219 - val_binary_accuracy: 0.9078\n",
            "Epoch 8/25\n",
            "312/312 [==============================] - 82s 263ms/step - loss: 0.2846 - binary_accuracy: 0.8748 - val_loss: 0.2254 - val_binary_accuracy: 0.9082\n",
            "Epoch 9/25\n",
            "312/312 [==============================] - 82s 263ms/step - loss: 0.2842 - binary_accuracy: 0.8744 - val_loss: 0.2257 - val_binary_accuracy: 0.9098\n",
            "Epoch 10/25\n",
            "312/312 [==============================] - 82s 261ms/step - loss: 0.2831 - binary_accuracy: 0.8744 - val_loss: 0.2174 - val_binary_accuracy: 0.9096\n",
            "Epoch 11/25\n",
            "312/312 [==============================] - 83s 266ms/step - loss: 0.2758 - binary_accuracy: 0.8806 - val_loss: 0.2279 - val_binary_accuracy: 0.8992\n",
            "Epoch 12/25\n",
            "312/312 [==============================] - 81s 261ms/step - loss: 0.2802 - binary_accuracy: 0.8806 - val_loss: 0.2141 - val_binary_accuracy: 0.9108\n",
            "Epoch 13/25\n",
            "312/312 [==============================] - 81s 260ms/step - loss: 0.2819 - binary_accuracy: 0.8761 - val_loss: 0.2137 - val_binary_accuracy: 0.9092\n",
            "Epoch 14/25\n",
            "312/312 [==============================] - 82s 262ms/step - loss: 0.2728 - binary_accuracy: 0.8813 - val_loss: 0.2097 - val_binary_accuracy: 0.9130\n",
            "Epoch 15/25\n",
            "312/312 [==============================] - 83s 264ms/step - loss: 0.2703 - binary_accuracy: 0.8836 - val_loss: 0.2100 - val_binary_accuracy: 0.9136\n",
            "Epoch 16/25\n",
            "312/312 [==============================] - 82s 261ms/step - loss: 0.2676 - binary_accuracy: 0.8861 - val_loss: 0.2065 - val_binary_accuracy: 0.9182\n",
            "Epoch 17/25\n",
            "312/312 [==============================] - 82s 262ms/step - loss: 0.2631 - binary_accuracy: 0.8863 - val_loss: 0.2135 - val_binary_accuracy: 0.9084\n",
            "Epoch 18/25\n",
            "312/312 [==============================] - 82s 261ms/step - loss: 0.2663 - binary_accuracy: 0.8824 - val_loss: 0.2056 - val_binary_accuracy: 0.9166\n",
            "Epoch 19/25\n",
            "312/312 [==============================] - 83s 266ms/step - loss: 0.2668 - binary_accuracy: 0.8855 - val_loss: 0.2051 - val_binary_accuracy: 0.9150\n",
            "Epoch 20/25\n",
            "312/312 [==============================] - 82s 261ms/step - loss: 0.2628 - binary_accuracy: 0.8888 - val_loss: 0.2011 - val_binary_accuracy: 0.9154\n",
            "Epoch 21/25\n",
            "312/312 [==============================] - 81s 260ms/step - loss: 0.2586 - binary_accuracy: 0.8885 - val_loss: 0.2127 - val_binary_accuracy: 0.9094\n",
            "Epoch 22/25\n",
            "312/312 [==============================] - 81s 258ms/step - loss: 0.2585 - binary_accuracy: 0.8874 - val_loss: 0.2322 - val_binary_accuracy: 0.9030\n",
            "Epoch 23/25\n",
            "312/312 [==============================] - 81s 261ms/step - loss: 0.2629 - binary_accuracy: 0.8849 - val_loss: 0.2098 - val_binary_accuracy: 0.9136\n",
            "Epoch 24/25\n",
            "312/312 [==============================] - 80s 256ms/step - loss: 0.2569 - binary_accuracy: 0.8884 - val_loss: 0.2073 - val_binary_accuracy: 0.9172\n",
            "Epoch 25/25\n",
            "312/312 [==============================] - 81s 258ms/step - loss: 0.2570 - binary_accuracy: 0.8904 - val_loss: 0.2166 - val_binary_accuracy: 0.9102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "av6vDVNkUQQq",
        "outputId": "9943a9fa-a906-4b4f-d3c8-80f104ff14ef"
      },
      "source": [
        "for layer in pretrained_base.layers[15:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "numOfEpoch = 10\n",
        "opt = SGD(0.0001)\n",
        "model.compile(opt, 'binary_crossentropy', ['binary_accuracy'])\n",
        "H = model.fit_generator(aug_train.flow(X_train, y_train, batch_size=64), \n",
        "                        steps_per_epoch=100,\n",
        "                        validation_data=(aug_test.flow(X_test, y_test, batch_size=64)),\n",
        "                        validation_steps=100,\n",
        "                        epochs=numOfEpoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2453 - binary_accuracy: 0.8923WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 [==============================] - 32s 301ms/step - loss: 0.2453 - binary_accuracy: 0.8923 - val_loss: 0.2064 - val_binary_accuracy: 0.9164\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 25s 244ms/step - loss: 0.2400 - binary_accuracy: 0.8980\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 24s 234ms/step - loss: 0.2443 - binary_accuracy: 0.8928\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 24s 244ms/step - loss: 0.2352 - binary_accuracy: 0.8963\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 25s 249ms/step - loss: 0.2456 - binary_accuracy: 0.8955\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 25s 245ms/step - loss: 0.2425 - binary_accuracy: 0.8975\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 24s 236ms/step - loss: 0.2359 - binary_accuracy: 0.9031\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 25s 248ms/step - loss: 0.2358 - binary_accuracy: 0.8998\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 24s 235ms/step - loss: 0.2325 - binary_accuracy: 0.8956\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 24s 242ms/step - loss: 0.2331 - binary_accuracy: 0.8975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVRUzQxuUUFE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "import pandas as pd\n",
        "history_frame = pd.DataFrame(H.history)\n",
        "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
        "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjBvKQQYUhDE"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}